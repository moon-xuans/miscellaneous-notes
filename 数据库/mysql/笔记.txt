MySQL
一、基础:
	1.MyISAM和InnoDB的区别：
		1.是否支持行级锁：
			MyISAM只有表级锁，而InnoDB支持行级锁和表级锁，默认是行级锁
		2.是否支持事务：
			MyISAM不提供事务支持，InnoDB提供事务支持（具有提交commit和回滚rollback的能力）
		3.是否支持外键：
			MyISAM不支持，而InnoDB支持
		4.InnoDB是聚集索引，MyISAM是非聚集索引。
		5.InnoDB不保存表的具体行数(因此查询的时候，需要全表扫描)，而MyISAM用一个变量保存了整个表的行数。
		6.是否支持数据库异常崩溃后的安全恢复
			MyISAM不支持，而InnoDB支持（恢复过程依赖redo log）
		7.是否支持MVCC
			MyISAM不支持，而InnoDB支持。
	2.表级锁和行级锁对比：
		表级锁：Mysql中粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源消耗比较少，加锁快，不会出现死锁。
		行级锁：粒度最下的一种锁，只针对当前操作的行进行加锁。加锁开销大，加锁慢，会出现死锁，行级锁能大大减少数据库操作的冲突。
	3.事务
		定义：事务是逻辑上的一组操作，要么都执行，要么都不执行（例子：转账过程，一方加，一方减）
	4.ACID特性
		1.原子性（Atomicity）：事务中的操作要么都发生，要么都不发生。
		2.一致性（Consistency）：事务前后数据的完整性必须保持一致。
		3.隔离性（Isolation）：事务的隔离性是多个用户并发访问数据时，数据库为每一个用户开启的事务，不能被其他事务的操作数据干扰，多个并发事务之间要相互隔离。
		4.持久性（Durability）：持久性是指一个事务一旦被提交，它对数据库的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响。
	5.并发事务带来那些问题？
		脏读：当一个事务正在访问数据并对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是”脏数据“。
		丢失修改：指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。
		不可重复读：指在一个事务内多次读同一数据。在这个事务中还没有结束时，另一个事务也访问该事务。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
		幻读：幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
	6.事务隔离级别有哪些(这是SQL标准下的)？
		1.READUNCOMMITTED（读取未提交）：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
		2.READCOMMITTED（读取已提交）：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
		3.REPEATABLEREAD（可重复读）：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但是幻读仍有可能发生。
		4.SERIALIZABLE（可串行化）：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读
		
		MySQL的默认隔离级别是什么？
			InnoDB存储引擎的默认支持的隔离级别是REPEATABLEREAD（可重复读）
			
		与SQL标准不同的地方在于InnoDB存储引擎在RR事务隔离级别下使用的是Next-Key Lock锁算法，因此可以避免幻读的产生，这与其他数据库(如SQL Server)是不同的。所以说InnoDB存储引擎的默认支持的隔离级别是RR已经可以完全保证事务的隔离性要求，即达到了SQL标准的SERIALIZABLE隔离级别。
		
		因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是RC.
		
		InnoDB存储引擎在分布式事务的情况下一般会用到SERIALIZABLE(串行化)隔离级别。
	7.数据库的三大范式
		1.第一范式(1NF):列不可再分
		2.第二范式(2NF):属性完全依赖于主键
		3.第三范式(3NF):属性不依赖于其他非主属性，属性直接依赖于主键
	8.其他的引擎
		Memory:表锁，存储在内容中，速度快，但会占用和数据量成正比的内存空间且数据在mysql重启时会丢失，默认使用HASH索引，检索效率非常高，但不适用于精确查找，主要用于那些内容变化不频繁的代码表。
	9.SQL优化手段
		1.查询语句中不要使用select * 
		2.尽量减少子查询，使用关联查询(left join,right join,inner join)替代
		3.减少使用IN或者NOT IN，使用exists，not exists或者关联查询语句替代
		4.or的查询尽量用union或者union all代替(在确认没有重复数据或者不用剔除重复数据时，union all会更好)
		5.应尽量避免where子句中使用!=代替<>操作符，否则将引擎放弃使用索引而进行全表扫描。
		6.应尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描，如:select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询:select id from t where num = 0.
	10.简单说一下drop、delete与truncate的区别
		SQL中的drop、delete、truncate都表示删除，但是三者有一些差别
		delete和truncate只删除表的数据不删除表的结构。速度，一般来说:drop > truncate > delete，delete语句是dml，这个操作会放到rollback segement中，事务提交之后才生效;如果有相应的trigger(触发器)，执行的时候将触发。truncate，drop是ddl，操作立即生效，原数据不放到rollback segment中，不能回滚，操作不触发trigger。
		
		truncate快的原因：
			首先，它是ddl语言，不需要放到rollback segment中，等待事务的提交再进行删除，而是操作立即生效，并且由于delete语句，需要rollback，它需要记录redo log日志，因此truncate要比delete快很多。
	11.什么是视图？
		视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，视图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表，它使得我们获取数据更容易，相比多表查询。
	12.什么是内连接、外连接、右外连接？
		内连接：匹配2张表中相关联的记录。
		左外连接：除了匹配2张表中相关联的记录外，还会匹配左表中剩余的记录，右表中未匹配到的字段用NULL表示。
		右外连接：除了匹配2张表中相关联的记录外，还会匹配右表中剩余的记录，左表中未匹配到的字段用NULL表示。
		在判定左表和右表时，要根据表名出现在Outer join的左右位置关系。
	13.大表如何优化？
		当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下:
			1.限定数据的范围：务必禁止不带任何限制数据范围条件的查询语句。
			2.读/写分离:经典的数据库拆分方案，主库负责写，从库负责读；
			3.垂直分区:
				根据数据库里面表的相关性进行拆分(将一个表拆分成两个表)，简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分成多张表。
				
				优点:可以使得列数据变小，在查询时减少读取的BLOCK数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。
				缺点：主键会出现冗余，需要管理冗余列，并会引起join操作，可以通过在应用层进行join来解决。此外，垂直分区会让事务变得更加复杂。
			4.水平分区
				保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。水平拆分可以支撑非常大的数据量。
				
				水平拆分是指数据表行的拆分，举个例子，可以将用户信息表拆分成多个用户信息表，这样就可以避免单一数据量过大对性能造成影响。
				需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库。
				
				水平拆分能够支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。
				
				数据库分片的两种常见方案：
					1.客户端代理：分片逻辑在应用层，封装在jar包中，通过修改或者封装JDBC层来实现。如当当网的Sharding-JDBC。
					2.中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。我们现在谈的Mycat。
	14.分库分表之后，id主键如何处理？
		因为要是分成多个表之后，每个表都是从1开始累加，这样是不对的，我们需要一个全局唯一的id来支持。
		生成全局id有下面这几种方式:
			1.UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标识比如文件的名字。
			2.数据库自增id：两台数据库分别设置不同 步长，生成不重复ID的策略来实现高可用。这种方式生成的id有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。
			3.利用redis生成id：性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。
			4.Twitter的snowflake算法，也就是雪花算法。
			5.美团的Leaf分布式ID生成系统：Leaf是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。
	15.MySQL中varchar与char的区别？varchar(30)中的30代表的含义？
		1.varchar与char的区别，char是一种固定长度的类型，varchar则是一种可变长度的类型。
		2.varchar(30)中30的含义是最多存放30个字符。varchar(30)和(130)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为ORDER BY col采用fixed_length计算col长度(memory引擎也一样).
		3.对效率要求高用char，对空间使用要求高用varchar。
		4.char列长度固定为创建表时声明的长度，长度值范围是1到255当CHAR值被存储时，它们被用空格填充到特定长度，检索CHAR值时需删除尾随空格。
	16.int(11)中的11代表什么含义？
		int(11)中的11，不影响字段存储的范围，只影响展示效果。
		声明字段是int类型的那一刻起，int就是占4个字节，一个字节8位，也就是可以表示的数字个数是2的32次方。
	17.什么是锁升级？
		1.MySQL行锁只能加在索引上，如果操作不走索引，就会升级为表锁。因为InnoDB的行锁是在索引上的，如果不走索引，自然就没法使用行锁了。
		2.当非唯一索引上记录数超过一定数量时，行锁也会升级为表锁。测试发现当非唯一索引相同内容不少于整个记录的二分之一时会升级为表锁。因为当非唯一索引相同的内容达到整个记录的二分之一时，索引需要的性能比全文索引还要大，查询语句优化时会选择不走索引，造成索引失效，行锁自然就会升级为表锁。
	18.说说悲观锁和乐观锁
		在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其他事务无法修改这些数据。修改删除数据时也要加锁，其他事务无法读取这些数据。
		乐观锁，大多数是基于数据版本记录机制实现的，比如mvcc。
	19.怎样尽量避免死锁的出现？
		1.设置获取锁的超时时间，至少能保证最差情况下，可以退出程序，不至于一直等待导致死锁；
		2.设置按照统一顺序访问资源，类似于串行执行；
		3.避免事务中的用户交叉；
		4.保持事务简短并在一个批处理中；
		5.使用低隔离级别；
	20.主键和候选键有什么区别？
		表的每一行都由主键唯一标识，一个表只有一个主键。主键也是候选键。按照惯例，候选键指定为主键，并且可以用于任何外键引用。
	21.什么是内联接、左外联接、右外联接？
		内联接（Inner Join）：匹配2张表中相关联的记录。
 		左外联接（Left Outer Join）：除了匹配2张表中相关联的记录外，还会匹配左表中剩余的记录，右表中未匹配到的字段用NULL表示。
		右外联接（Right Outer Join）：除了匹配2张表中相关联的记录外，还会匹配右表中剩余的记录，左表中未匹配到的字段用NULL表示。在判定左表和右表时，要根据表名出现在Outer Join的左右位置关系。
	22.datetime、timestamp和数值型时间戳	
		日期类型	存储空间 	日期格式			日期范围									是否存在时区问题
		DateTime	8字节		YYYY-MM-DD HH:MM:SS	1000-01-01 00:00:00 ~ 9999-12-31 23:59:59	是
		Timestamp	4字节		YYYY-MM-DD HH:MM:SS	1970-01-01 00:00:01 ~ 2037-12-31 23:59:59	否
		时间戳		4字节		全数字如1578707612	1970-01-01 00:00:01之后的时间				否
						
二、索引:
	1.什么是索引？（相当于目录的作用）
		索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有：B树，B+树和Hash。
	2.索引的优缺点
		优点：可以大大加快数据的检索速度（大大减少的检索的数据量），这也是创建索引的最主要原因。
		缺点：
			1.创建索引和维护索引需要耗费许多时间
			2.占用物理存储空间
	3.B树和B+树的区别
		1.B树的所有节点既存放键也存放数据；而B+树只有叶子节点存放key和data，其他节点只存放key。
		2.B树的叶子节点都是独立的；B+树的叶子节点有一条引用链指向与它相邻的叶子节点
		3.B树的检索过程相当于范围内的每个节点的关键字都做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。
	4.索引类型
		主键索引（Primary Key）：
			数据库的主键列使用的就是主键索引。
			一张数据表有只能有一个主键，并且主键不能为null，不能重复。
			在Mysql的InnoDB的表中，当没有显示的指定表的主键时，InnoDB会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则InnoDB将会自动创建一个6Byte的自增主键。
		二级索引：
			二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。
			
			唯一索引，普通索引，前缀索引等索引属于二级索引。
				唯一索引（Unique Key）：唯一索引的属性列不能出现重复的数据，但是允许数据为null，一张表允许创建多个唯一索引。
				
				普通索引：普通索引的唯一作用就是为了快速查找数据，一张表允许创建多个普通索引，并允许数据重复和NULL。
				
				前缀索引（Prefix）：前缀索引只适用于字符串类型的数据，前缀索引是对文本的前几个字符创建索引。
				
				全文索引（Full Text）：全文索引主要是为了大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。
	5.聚集索引与非聚集索引
		聚集索引：
			定义：聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。
			
			在Mysql中，InnoDB引擎的表的.ibd文件就包含了该表的索引和数据，对于InnoDB引擎表来说，该表的索引（B+树）的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。
			
			优点：聚集索引的查询速度非常的快。
			缺点：
				1.依赖于有序的数据
				2.更新代价大
		非聚集索引：
			定义：非聚集索引即索引结构和数据分开存放的索引。二级索引属于非聚集索引。
			
			MYISAM引擎的表的.MYI文件包含了表的索引，该表的索引（B+树）的每个非叶子节点存储索引，叶子节点存储索引和索引对应数据的指针，执行.MYD文件的数据。（非聚集索引的叶子节点并不一定存放数据的指针，因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据）
			
			优点：更新代价比聚集索引要小。
			缺点：
				1.跟聚集索引一样，非聚集索引也依赖于有序的数据。
				2.可能会二次查询（回表）
		
		非聚集索引一定回表查询吗（覆盖索引）？
			非聚集索引不一定回表查询。
			例：SELECT name FROM table WHERE name = 'guang19';
			那么这个索引的key本身就是name，查到对应的name直接返回就行了，无需回表查询。
	6.覆盖索引
		定义：覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，无需回表查询。
		（例子：如主键索引，如果一条SQL需要查询主键，那么正好根据主键索引就可以查到主键。
		再例如普通索引，如果一条SQL需要查询name，name字段正好有索引。那么直接根据这个索引就可以查到数据，也无需回表。
		）
	7.创建索引的注意事项
		1.选择合适的字段创建索引:
			不为NULL的字段；
			被频繁查询的字段；
			被作为条件查询的字段；
			频繁需要排序的字段；
			被经常频繁用于连接的字段；
		2.被频繁更新的字段应该慎重建立索引。
		3.尽可能的考虑建立联合索引而不是单列索引；
		4.注意避免冗余索引；
		5.考虑在字符串类型的字段上使用前缀索引代替普通索引。
	8.使用索引的一些建议
		1.对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引
		2.避免 where 子句中对字段施加函数，这会造成无法命中索引。
		3.在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。
		4.删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 schema_unused_indexes视图来查询哪些索引从未被使用
		5.在使用 limit offset 查询缓慢时，可以借助索引来提高性能
	9.索引创建原则
		单列索引：单列索引即由一列属性组成的索引。
		联合索引（多列索引）：联合索引即由多列属性组成索引。
		最左前缀原则：
			假设创建的联合索引由三个字段组成：ALTER TABLE table ADD INDEX index_name(num,name,age)
			那么当查询的条件有num/(num And name)/(num AND name AND age)时，索引才生效。所以在创建联合索引时，尽量把查询最频繁的那个字段作为最左（第一个）字段。查询的时候也尽量以这个字段为第一条件
			
		使用索引一定能提高查询性能吗？
		大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。

三、三大日志:
	二进制日志binlog（归档日志）和事务日志redo log（重做日志）和 undo log（回滚日志）
	1.redo log 
		redo log（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力。比如 MySQL实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的持久性与完整性。
		
		MySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（redo log buffer）里，接着刷盘到 redo log 文件里。
		1.1.刷盘时机
			InnoDB 存储引擎为 redo log 的刷盘策略提供了 innodb_flush_log_at_trx_commit 参数，它支持三种策略：
				0：设置为 0 的时候，表示每次事务提交时不进行刷盘操作
				1：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）
				2：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache

			innodb_flush_log_at_trx_commit 参数默认为 1 ，也就是说当事务提交时会调用 fsync 对 redo log 进行刷盘
			另外，InnoDB 存储引擎有一个后台线程，每隔1 秒，就会把 redo log buffer 中的内容写到文件系统缓存（page cache），然后调用 fsync 刷盘。
			
			也就是说，一个没有提交事务的 redo log 记录，也可能会刷盘。
			为什么呢？
			因为在事务执行过程 redo log 记录是会写入redo log buffer 中，这些 redo log 记录会被后台线程刷盘。
			
			除了后台线程每秒1次的轮询操作，还有一种情况，当 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动刷盘。
			
			不同刷盘策略的情况:
				0:
					为0时，如果MySQL挂了或宕机可能会有1秒数据的丢失。
				1: 
					只要事务提交成功，redo log记录就一定在硬盘里，不会有任何数据丢失。
					如果事务执行期间MySQL挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失。
				2:
					只要事务提交成功，redo log buffer中的内容只写入文件系统缓存（page cache）。
					如果仅仅只是MySQL挂了不会有任何数据丢失，但是宕机可能会有1秒数据的丢失。
		1.2.日志文件组
			硬盘上存储的 redo log 日志文件不只一个，而是以一个日志文件组的形式出现的，每个的redo日志文件大小都是一样的。比如可以配置为一组4个文件，每个文件的大小是 1GB，整个 redo log 日志文件组可以记录4G的内容。它采用的是环形数组形式，从头开始写，写到末尾又回到头循环写.
			
			在个日志文件组中还有两个重要的属性，分别是 write pos、checkpoint
				write pos 是当前记录的位置，一边写一边后移
				checkpoint 是当前要擦除的位置，也是往后推移
			每次刷盘 redo log 记录到日志文件组中，write pos 位置就会后移更新。
			每次 MySQL 加载日志文件组恢复数据时，会清空加载过的 redo log 记录，并把 checkpoint 后移更新。
			write pos 和 checkpoint 之间的还空着的部分可以用来写入新的 redo log 记录。
			
			如果 write pos 追上 checkpoint ，表示日志文件组满了，这时候不能再写入新的 redo log 记录，MySQL 得停下来，清空一些记录，把 checkpoint 推进一下。
		1.3.小结
			只要每次把修改后的数据页直接刷盘不就好了，还有 redo log 什么事？
			实际上，数据页大小是16KB，刷盘比较耗时，可能就修改了数据页里的几 Byte 数据，有必要把完整的数据页刷盘吗？
			而且数据页刷盘是随机写，因为一个数据页对应的位置可能在硬盘文件的随机位置，所以性能是很差。
			如果是写 redo log，一行记录可能就占几十 Byte，只包含表空间号、数据页号、磁盘文件偏移 量、更新值，再加上是顺序写，所以刷盘速度很快。
			所以用 redo log 形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强。
	2.bin log日志
		redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎。
		而 binlog 是逻辑日志，记录内容是语句的原始逻辑，属于MySQL Server 层。
		不管用什么存储引擎，只要发生了表数据更新，都会产生 binlog 日志。
		那 binlog 到底是用来干嘛的？
		可以说MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。
		2.1.记录格式
			binlog 日志有三种格式，可以通过binlog_format参数指定。
				 statement
				 row
				 mixed
			指定statement，记录的内容是SQL语句原文
			同步数据时，会执行记录的SQL语句，但是有个问题，update_time=now()这里会获取当前系统时间，直接执行会导致与原库的数据不一致。
			
			为了解决这种问题，我们需要指定为row，记录的内容不再是简单的SQL语句了，还包含操作的具体数据。
			row格式记录的内容看不到详细信息，要通过mysqlbinlog工具解析出来。
			这样就能保证同步数据的一致性，通常情况下都是指定为row，这样可以为数据库的恢复与同步带来更好的可靠性。
			但是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗IO资源，影响执行速度。

			所以就有了一种折中的方案，指定为mixed，记录的内容是前两者的混合。
			MySQL会判断这条SQL语句是否可能引起数据不一致，如果是，就用row格式，否则就用statement格式
		2.2.写入机制
			binlog的写入时机也非常简单，事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。
			因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache。
			我们可以通过binlog_cache_size参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（Swap）。
			
			事实上这一块，有两步操作:
				write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快
				fsync，才是将数据持久化到磁盘的操作

			write和fsync的时机，可以由参数sync_binlog控制，默认是0。
			为0的时候，表示每次提交事务都只write，由系统自行判断什么时候执行fsync。
			虽然性能得到提升，但是机器宕机，page cache里面的 binlog 会丢失。

			为了安全起见，可以设置为1，表示每次提交事务都会执行fsync，就如同binlog 日志刷盘流程一样。

			最后还有一种折中方式，可以设置为N(N>1)，表示每次提交事务都write，但累积N个事务后才fsync。
			在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。
			同样的，如果机器宕机，会丢失最近N个事务的binlog日志。
	3.两阶段提交
		redo log（重做日志）让InnoDB存储引擎拥有了崩溃恢复能力。
		binlog（归档日志）保证了MySQL集群架构的数据一致性。
		虽然它们都属于持久化的保证，但是侧重点不同。
		在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样。
		
		回到正题，redo log与binlog两份日志之间的逻辑不一致，会出现什么问题？
		我们以update语句为例，假设id=2的记录，字段c值是0，把字段c值更新成1，SQL语句为update T set c=1 where id=2。
		假设执行过程中写完redo log日志后，binlog日志写期间发生了异常，会出现什么情况呢？	由于binlog没写完就异常，这时候binlog里面没有对应的修改记录。因此，之后用binlog日志恢复数据时，就会少这一次更新，恢复出来的这一行c值是0，而原库因为redo log日志恢复，这一行c值是1，最终数据不一致。

		为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。
		原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交。
		使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。

		再看一个场景，redo log设置commit阶段发生异常，那会不会回滚事务呢？
		并不会回滚事务,虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据。
	4.undo log
		我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在MySQL中，恢复机制是通过回滚日志（undolog）实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用回滚日志中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。
	5.总结
		MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。
		MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。
四、mvcc
	作用：在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能。同时还可以解决脏读、幻读、不可重复读等事务隔离问题，但不能解决更新丢失问题。

	1.一致性非锁定读和锁定读
		1.1.一致性非锁定读
			对于 一致性非锁定读的实现，通常做法是加一个版本号或者时间戳字段，在更新数据的同时版本号 + 1 或者更新时间戳。查询时，将当前可见的版本号与对应记录的版本号进行比对，如果记录的版本小于可见版本，则表示该记录可见

			在 InnoDB 存储引擎中，多版本控制就是对非锁定读的实现。如果读取的行正在执行 DELETE 或 UPDATE 操作，这时读取操作不会去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)

			在 RR 和 RC 两个隔离级别下，如果是执行普通的 select 语句则会使用一致性非锁定读（MVCC）。并且在 RR 下 MVCC 实现了可重复读和防止部分幻读	
		1.2.锁定读
			如果执行的是下列语句，就是 锁定读
				select ... lock in share mode
				select ... for update
				insert、update、delete 操作

			在锁定读下，读取的是数据的最新版本，这种读也被称为 当前读。锁定读会对读取到的记录加锁：
				select ... lock in share mode：对记录加 S 锁，其它事务也可以加S锁，如果加 x 锁则会被阻塞
				select ... for update、insert、update、delete：对记录加 X 锁，且其它事务不能加任何锁

			在一致性非锁定读下，即使读取的记录已被其它事务加上 X 锁，这时记录也是可以被读取的，即读取的快照数据。在 RR下 MVCC 防止了部分幻读，这边的 “部分” 是指在一致性非锁定读情况下，只能读取到第一次查询之前所插入的数据。但是，如果是当前读(锁定读)，每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。所以， InnoDB 在实现RR时，如果执行的是当前读，则会对读取的记录使用 Nextkey Lock ，来防止其它事务在间隙间插入数据.
	2.InnoDB对MVCC的实现
		MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改。
		2.1.隐藏字段
			在内部，InnoDB 存储引擎为每行数据添加了三个 隐藏字段  ：
				 DB_TRX_ID（6字节）：表示最后一次插入或更新该行的事务 id。此外，delete 操作在内部被视为更新，只不过会在记录头 Record header 中的 deleted_flag 字段将其标记为已删除
				 DB_ROLL_PTR（7字节） 回滚指针，指向该行的 undo log 。如果该行未被更新，则为空
				 DB_ROW_ID（6字节）：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该 id 来生成聚簇索引
		2.2.ReadView
			Read View 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”
			主要有以下字段：
				1.m_low_limit_id：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见
				2.m_up_limit_id：活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id为m_low_limit_id。小于这个 ID 的数据版本均可见
				3.m_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务
				4.m_creator_trx_id：创建该 Read View 的事务 ID
		2.3.undolog
			undo log 主要有两个作用：
				1.当事务回滚时用于将数据恢复到修改前的样子
				2.另一个作用是 MVCC ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 undo log 读取之前的版本数据，以此实现非锁定读

			在 InnoDB 存储引擎中 undo log 分为两种： insert undo log 和 update undo log：
				1. insert undo log ：指在 insert 操作中产生的 undo log。因为 insert 操作的记录只对事务本身可见，对其他事务不可见，故该 undo log 可以在事务提交后直接删除。不需要进行 purge 操作
				2.update undo log ：update 或 delete 操作中产生的 undo log。该 undo log可能需要提供 MVCC 机制，因此不能在事务提交时就进行删除。提交时放入 undo log 链表，等待 purge线程 进行最后的删除

			不同事务或者相同事务的对同一记录行的修改，会使该记录行的 undo log 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。
		2.4.数据可见性算法
			在 InnoDB 存储引擎中，创建一个新事务后，执行每个 select 语句前，都会创建一个快照（Read View），快照中保存了当前数据库系统中正处于活跃的事务的 ID 号。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）。当用户在这个事务中要读取某个记录行的时候，InnoDB 会将该记录行的 DB_TRX_ID 与 Read View 中的一些变量及当前事务 ID 进行比较，判断是否满足可见性条件
			
			1. 如果记录 DB_TRX_ID < m_up_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之前就提交了，所以该记录行的值对当前事务是可见的
			2. 如果 DB_TRX_ID >= m_low_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之后才修改该行，所以该记录 行的值对当前事务不可见。跳到步骤 5
			3. m_ids 为空，则表明在当前事务创建快照之前，修改该行的事务就已经提交了，所以该记录行的值对当前事务是可见的
			4. 如果 m_up_limit_id <= DB_TRX_ID < m_low_limit_id，表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表 m_ids 进行查找（源码中是用的二分查找，因为是有序的）
				1.如果在活跃事务列表 m_ids 中能找到 DB_TRX_ID，表明：① 在当前事务创建快照前，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了，但没有提交；或者 ② 在当前事务创建快照后，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了。这些情况下，这个记录行的值对当前事务都是不可见的。跳到步骤 5
				2.在活跃事务列表中找不到，则表明“id 为 trx_id 的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见
			5. 在该记录行的 DB_ROLL_PTR 指针所指向的 undo log 取出快照记录，用快照记录的 DB_TRX_ID 跳到步骤 1 重新开始判断，直到找到满足的快照版本或返回空
	3.在RC和RR隔离级别下MVCC的差异
		在事务隔离级别 RC 和 RR （InnoDB 存储引擎的默认事务隔离级别）下，InnoDB 存储引擎使用 MVCC（非锁定一致性读），但它们生成 Read View 的时机却不同
			在 RC 隔离级别下的 每次select 查询前都生成一个Read View (m_ids 列表)
			在 RR 隔离级别下只在事务开始后 第一次select 数据前生成一个Read View（m_ids 列表）
	4.mvcc+nextkeylock防止幻读
		InnoDB存储引擎在 RR 级别下通过 MVCC和 Nextkey Lock 来解决幻读问题：
			1、执行普通 select，此时会以 MVCC 快照读的方式读取数据
			在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”
			2、执行 select...for update/lock in share mode、insert、update、delete 等当前读
			在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Nextkey Lock 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。
五、SQL语句的执行顺序
	1.基本架构分析
		1.1.MySQL主要分为两层Server层和存储引擎层:
			Server层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。
             存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自带的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。
		1.2.Server层基本组件介绍
			1) 连接器
			连接器主要和身份认证和权限相关的功能相关.
			主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即使管理员修改了该用户的权限，该用户也是不受影响的。
			2) 查询缓存(MySQL 8.0 版本后移除)
			查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。

			连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 KeyValue 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。

			MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。

			所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。

			MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。
			3) 分析器
			MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：

			第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。

			第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。

			完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。
			4) 优化器
			优化器的作用就是它认为的最优的执行方案去执行，比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。

			可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。
			5) 执行器
			当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。
	2.语法分析
		sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。
		2.1.查询语句
			例：select * from tb_student  A where A.age='18' and A.name=' 张三 ';
			流程如下:
				1.先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接返回缓存，如果没有，执行下一步。
				2.通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
				3.接下来就是优化器进行确定执行方案
					那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。
				4.进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。
		2.2.更新语句
			例: update tb_student A set A.age='19' where A.name=' 张三 ';
			这条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候要记录日志，这就会引入日志模块了，MySQL 自带的日志模块是 binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志），我们就以 InnoDB 模式下来探讨这个语句的执行流程。
			流程如下:
				1.先查询到张三这一条数据，如果有缓存，也是会用到缓存。
				2.然后拿到查询的结果，把数据更新，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。
				3.执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。
				4.更新完成。
六、慢SQL
	查看MySQL是否启用了查看慢SQL的日志文件

	（1） 查看慢SQL日志是否启用

	mysql> show variables like 'log_slow_queries'; 
	+------------------+-------+
	| Variable_name    | Value |
	+------------------+-------+
	| log_slow_queries | ON    |
	+------------------+-------+
	1 row in set (0.00 sec)

	（2） 查看执行慢于多少秒的SQL会记录到日志文件中
	mysql> show variables like 'long_query_time';
	+-----------------+-------+
	| Variable_name   | Value |
	+-----------------+-------+
	| long_query_time | 1     |  
	+-----------------+-------+
	1 row in set (0.00 sec)

	这里value=1， 表示1秒

	 
	2. 配置my.ini文件（inux下文件名为my.cnf）， 查找到[mysqld]区段，增加日志的配置，如下示例：
	[mysqld]
	log="C:/temp/mysql.log"
	log_slow_queries="C:/temp/mysql_slow.log"
	long_query_time=1
	 
	log指示日志文件存放目录；
	log_slow_queries指示记录执行时间长的sql日志目录；
	long_query_time指示多长时间算是执行时间长，单位s。
	 
	Linux下这些配置项应该已经存在，只是被注释掉了，可以去掉注释。但直接添加配置项也OK啦。
七、隔离级别的实现
	MySQL事务提出了4个不同的隔离级别，而这些隔离级别的实现本质上就是通过加锁，解锁来实现的。那么我们该何时加锁，占锁多长时间，何时解锁呢？要通过三级封锁协议。三级封锁协议顾名思义是3个不同级别的封锁协议，它们是以何时加锁，何时解锁来区分的。下面我们看一下具体的定义：

		1.一级封锁协议：事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。 一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。使用一级封锁协议可以解决丢失修改问题。在一级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，它不能保证可重复读和不读“脏”数据。
		2.二级封锁协议：在一级封锁协议之上，事务T在读取数据R之前必须先对其加S锁，读完后方可释放S锁。 二级封锁协议除防止了丢失修改，还可以进一步防止读“脏”数据。但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。
		3.三级封锁协议 ：在一级封锁协议之上，事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。 三级封锁协议除防止了丢失修改和不读“脏”数据外，还进一步防止了不可重复读。
八、Limit关键字的使用
	1.Limit的效率高？
		常说的Limit的执行效率高，是对于一种特定条件下来的说:即数据库的数量很大，但是只需要查询一部分数据的情况。
		
		高效率的原理是：避免全表扫描，提高查询效率。
		比如:每个用户的email是唯一的，如果用户使用email作为用户名登录的话，就需要查询email对应的一条记录。
		SELECT * FROM t_user WHERE email=?;
		上面的语句实现了查询email对应的一条用户信息，但是由于email这一列没有加索引，会导致全表扫描，效率会很低。
		SELECT * FROM t_user WHERE email=? LIMIT 1;
		
		加上LIMIT1,只要找到了对应的一条记录，就不会继续向下扫描了，效率会大大提高。
	2.Limit的效率低？
		在一种情况下，使用limit效率低，那就是:只使用limit来查询语句，并且偏移量特别大的情况。
		
		做以下实验:
		语句1：select * from table limit 150000,1000;
		分析:虽然实现了分页功能，但随着查询偏移的增大，尤其查询偏移大于10万以后，查询时间将急剧增加。这种分页查询会从数据库第一条记录开始扫描，所以越往后，查询速度越慢，而且查询的数据越多，也会拖慢总查询。
		语句2:select * from table where id >= 150000 limit 1000;
		语句1为0.2077秒；语句2:0.0063秒
		分析:这种查询能够极大地优化查询速度，基本能够在几十毫秒之内完成。
		两条语句的时间比是:语句1/语句2=32.968
		
		比较以上的数据时，我们可以发现where...limit...性能基本稳定，受偏移量和行数的影响不大，而单纯采用limit的话，受偏移量的影响很大，当偏移量大到一定值后性能还是大幅下降。不过在数据量不大的情况下，两者的区别不大。
		
		所以应当先使用where等查询语句，配合limit使用，效率才高。
		
