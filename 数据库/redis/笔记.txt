八股文
	1.什么是Redis?
		Redis 是一个开源（BSD 许可）、基于内存、支持多种数据结构的存储系统，可以作为数据库、缓
		存和消息中间件。它支持的数据结构有字符串（strings）、哈希（hashes）、列表（lists）、集合
		（sets）、有序集合（sorted sets）等，除此之外还支持 bitmaps、hyperloglogs 和地理空间（
		geospatial ）索引半径查询等功能。
		
		它内置了复制（Replication）、LUA 脚本（Lua scripting）、LRU 驱动事件（LRU eviction）、事
		务（Transactions）和不同级别的磁盘持久化（persistence）功能，并通过 Redis 哨兵（哨兵）和
		集群（Cluster）保证缓存的高可用性（High availability）
	2.为什么Redis单线程模型效率也能那么高？
		1. C语言实现，效率高
		2. 纯内存操作
		3. 基于非阻塞的IO复用模型机制
		4. 单线程的话就能避免多线程的频繁上下文切换问题
		5. 丰富的数据结构（全称采用hash结构，读取速度非常快，对数据存储进行了一些优化，比如亚
		索表，跳表等）
	3.说说Redis的线程模型
		epoll
	4.pipeline有什么好处，为什么要用？
		使用 pipeline（管道）的好处在于可以将多次 I/O 往返的时间缩短为一次，但是要求管道中执行的
		指令间没有因果关系。
		
		用 pipeline 的原因在于可以实现请求/响应服务器的功能，当客户端尚未读取旧响应时，它也可以
		处理新的请求。如果客户端存在多个命令发送到服务器时，那么客户端无需等待服务端的每次响应
		才能执行下个命令，只需最后一步从服务端读取回复即可。
	5.怎么使用Redis实现消息队列？
		一般使用 list 结构作为队列， rpush 生产消息， lpop 消费消息。当 lpop 没有消息的时候，要适当
		sleep 一会再重试。
		
		1.面试官可能会问可不可以不用 sleep 呢？
		list 还有个指令叫 blpop ，在没有消息的时候，它会阻塞住直到消息到来。
		2.面试官可能还问能不能生产一次消费多次呢？
		使用 pub / sub 主题订阅者模式，可以实现 1:N的消息队列。
		3.面试官可能还问 pub / sub 有什么缺点？
		在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。
		4.面试官可能还问 Redis 如何实现延时队列？
		使用sortedset ，拿时间戳作为 score ，消息内容作为 key 调用 zadd 来生产消息，消费者用zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。
		
		面试扩散：很多面试官上来就直接这么问： Redis 如何实现延时队列？
	6.说说你对Redis事务的理解
		1.什么是 Redis 事务？原理是什么？
			Redis 中的事务是一组命令的集合，是 Redis 的最小执行单位。它可以保证一次执行多个命令，每
			个事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序地执行。服务端在执行事务
			的过程中，不会被其他客户端发送来的命令请求打断。
			它的原理是先将属于一个事务的命令发送给 Redis，然后依次执行这些命令。
		2.Redis 事务的注意点有哪些？
			需要注意的点有：
			1.Redis 事务是不支持回滚的，不像 MySQL 的事务一样，要么都执行要么都不执行；
			2.Redis服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。直到事务命令全部执行完毕才会执行其他客户端的命令。
		
		3.Redis 事务为什么不支持回滚？
			Redis 的事务不支持回滚，但是执行的命令有语法错误，Redis 会执行失败，这些问题可以从程序层
			面捕获并解决。但是如果出现其他问题，则依然会继续执行余下的命令。这样做的原因是因为回滚
			需要增加很多工作，而不支持回滚则可以保持简单、快速的特性。
			
		Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的 Redis会将一个事务中的
		所有命令序列化，然后按顺序执行。 1.redis 不支持回滚“Redis 在事务失败时不进行回滚，而是继
		续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。 2.如果在一个事务中的命令出现错
		误，那么所有的命令都不会执行； 3.如果在一个事务中出现运行错误，那么正确的命令会被执行。

		1）MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发
		送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有
		队列中的命令才会被执行。 2）EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回
		值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。 3）通过调用DISCARD，客户
		端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。 4）WATCH 命令可以
		为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修
		改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
	---------------------------------------------------------------------------------
	7.什么是bigkey?会存在什么影响？
		bigkey 是指键值占用内存空间非常大的 key。例如一个字符串 a 存储了 200M 的数据。
		
		bigkey 的主要影响有：
			1.网络阻塞；获取 bigkey 时，传输的数据量比较大，会增加带宽的压力。
			2.超时阻塞；因为 bigkey 占用的空间比较大，所以操作起来效率会比较低，导致出现阻塞的可能性增加。
			3.导致内存空间不平衡；一个 bigkey 存储数据量比较大，同一个 key 在同一个节点或服务器中存储，会造成一定影响。
	8.是否使用过redis cluster集群，集群的原理是什么？
		使用过 Redis 集群，它的原理是：
			1.所有的节点相互连接
			2.集群消息通信通过集群总线通信，集群总线端口大小为客户端服务端口 + 10000（固定值）
			3.节点与节点之间通过二进制协议进行通信
			4.客户端和集群节点之间通信和通常一样，通过文本协议进行
			5.集群节点不会代理查询
			6.数据按照 Slot 存储分布在多个 Redis 实例上
			7.集群节点挂掉会自动故障转移
			8.可以相对平滑扩/缩容节点
	9.Redis常见性能问题和解决方案有哪些？
		1.Master  最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件；
		2.如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次；
		3.为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网内； 
		4.尽量避免在压力很大的主库上增加从库；
		5.主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- 
		Slave3….；这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂
		了，可以立刻启用 Slave1 做 Master，其他不变。
	10.假如Redis里面有1亿个key，其中有10w个key是以固定的已知的前缀开头的，如何将它们全部找出来？
		我们可以使用 keys 命令和 scan 命令，但是会发现使用 scan 更好。
			1. 使用 keys 命令
				直接使用 keys 命令查询，但是如果是在生产环境下使用会出现一个问题，keys 命令是遍历查询
				的，查询的时间复杂度为 O(n)，数据量越大查询时间越长。而且 Redis 是单线程，keys 指令会导
				致线程阻塞一段时间，会导致线上 Redis 停顿一段时间，直到 keys 执行完毕才能恢复。这在生产
				环境是不允许的。除此之外，需要注意的是，这个命令没有分页功能，会一次性查询出所有符合条
				件的 key 值，会发现查询结果非常大，输出的信息非常多。所以不推荐使用这个命令。
			2. 使用 scan 命令
				scan 命令可以实现和 keys 一样的匹配功能，但是 scan 命令在执行的过程不会阻塞线程，并且查
				找的数据可能存在重复，需要客户端操作去重。因为 scan 是通过游标方式查询的，所以不会导致
				Redis 出现假死的问题。Redis 查询过程中会把游标返回给客户端，单次返回空值且游标不为 0，则
				说明遍历还没结束，客户端继续遍历查询。scan 在检索的过程中，被删除的元素是不会被查询出来
				的，但是如果在迭代过程中有元素被修改，scan 不能保证查询出对应元素。相对来说，scan 指令
				查找花费的时间会比 keys 指令长。
	11.缓存和数据库谁先更新呢？
		1.解决方案
			1. 写请求过来，将写请求缓存到缓存队列中，并且开始执行写请求的具体操作（删除缓存中的数
			据，更新数据库，更新缓存）。
			2. 如果在更新数据库过程中，又来了个读请求，将读请求再次存入到缓存队列（可以搞n个队
			列，采用key的hash值进行队列个数取模hash%n，落到对应的队列中，队列需要保证顺序性）
			中，顺序性保证等待队列前的写请求执行完成，才会执行读请求之前的写请求删除缓存失败，
			直接返回，此时数据库中的数据是旧值，并且与缓存中的数据是一致的，不会出现缓存一致性
			的问题。
			3. 写请求删除缓存成功，则更新数据库，如果更新数据库失败，则直接返回，写请求结束，此时
			数据库中的值依旧是旧值，读请求过来后，发现缓存中没有数据， 则会直接向数据库中请求，
			同时将数据写入到缓存中，此时也不会出现数据一致性的问题。
			4. 更新数据成功之后，再更新缓存，如果此时更新缓存失败，则缓存中没有数据，数据库中是新
			值 ，写请求结束，此时读请求还是一样，发现缓存中没有数据，同样会从数据库中读取数据，
			并且存入到缓存中，其实这里不管更新缓存成功还是失败， 都不会出现数据一致性的问题。
			
			上面这方案解决了数据不一致的问题，主要是使用了串行化，每次操作进来必须按照顺序进行。如
			果某个队列元素积压太多，可以针对读请求进行过滤，提示用户刷新页面，重新请求。
		
		2.潜在的问题，留给大家自己去想吧，因为这个问题属于发散性。
			1.请求时间过长，大量的写请求堆压在队列中，一个读请求来得等都写完了才可以获取到数据。
			2.读请求并发高
			3.热点数据路由问题，导致请求倾斜。
	12.Redis如何解决key冲突？
		Redis 如果 key 相同，后一个 key 会覆盖前一个 key。如果要解决 key 冲突，最好给 key 取好名区
		分开，可以按业务名和参数区分开取名，避免重复 key 导致的冲突
	
	------------------------------------------------------------------------------------------------------  

1.redis的基本数据类型
	1.String
		string 是Redis的最基本的数据类型，一个key 对应一个 value。redis 中一个字符串 value 最多可以是 512M。
		1.应用场景	
			对于string数据类型，因为string类型是二进制安全的，可以用来存放图片，视频等内容，另外由于Redis的高性能读写功能，而string类型的value也可以是数字，可以用作计数器（INCR,DECR），比如分布式环境中统计系统的在线人数，秒杀等。
		---------------------------------------------------------------------------------
		2.相关命令
			①、ttl 命令是返回 key 的剩余过期时间，单位为秒。	②、mset和mget这种批量处理命令，能够极大的提高操作效率。因为一次命令执行所需要的时间=1次网络传输时间+1次命令执行时间，n个命令耗时=n次网络传输时间+n次命令执行时间，而批量处理命令会将n次网络时间缩减为1次网络时间，也就是1次网络传输时间+n次命令处理时间。
			但是需要注意的是，Redis是单线程的，如果一次批量处理命令过多，会造成Redis阻塞或网络拥塞（传输数据量大）。
			③、setnx可以用于实现分布式锁。
		
	2.hash
		hash 是一个键值对集合，是一个 string 类型的 key和 value 的映射表，key 还是key，但是value是一个键值对（key-value）。类比于 Java里面的 Map<String,Map<String,Object>> 集合。
		1.应用场景	
			对于 hash 数据类型，value 存放的是键值对，比如可以做单点登录存放用户信息。
	3.list
		list列表，它是简单的字符串列表，按照插入顺序排序，你可以添加一个元素到列表的头部（左边）或者尾部（右边），它的底层实际上是个链表。
		
		列表有两个特点：
	　　一、有序
	　　二、可以重复
	　　这两个特点要注意和后面介绍的集合和有序集合相对比。
	
		1.应用场景
			对于 list 数据类型，可以实现简单的消息队列，另外可以利用lrange命令，做基于redis的分页功能	
	4.set
		Redis 的 set 是 string 类型的无序集合。
		
		相对于列表，集合也有两个特点：
		一、无序
		二、不可重复
		
		1.应用场景
			对于set数据类型，由于底层是字典实现的，查找元素特别快，另外set数据类型不允许重复，利用这两个特性我们可以进行全局去重，比如在用户注册模块，判断用户名是否注册；另外就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
			
	5.zset
		zset（sorted set 有序集合），和上面的set 数据类型一样，也是 string 类型元素的集合，但是它是有序的。
		1.应用场景
			对于 zset 数据类型，有序的集合，可以做范围查找，排行榜应用，取 TOP N 操作等。
2.底层数据结构
	1.简单动态字符串
		Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。
		
		1.SDS结构:
			struct sdshdr{
				//记录buf数组中已使用字节的数量
				//等于 SDS 保存字符串的长度
				int len;
				//记录 buf 数组中未使用字节的数量
				int free;
				//字节数组，用于保存字符串
				char buf[];
			}
		
		2.相对于 C 语言对于字符串的定义，多出了 len 属性以及 free 属性。为什么不使用C语言字符串实现，而是使用 SDS呢？这样实现有什么好处？
			①、常数复杂度获取字符串长度
		　　	由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 
				语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。
		　　②、杜绝缓冲区溢出
		　　	我们知道在 C 语言中使用 strcat 	
				函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 free属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。
		　　③、减少修改字符串的内存重新分配次数	　　		
				C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。
		　　	而对于SDS，由于len属性和free属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：
					1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。　　				  		2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用free 	属性将这些字节的数量记录下来，等待后续使用。
					（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）
		　　④、二进制安全
				因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 buf里面的元素，并且SDS不是以空字符来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。
		　　⑤、兼容部分 C 字符串函数
		　		虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符结尾的惯例，这样可以重用 C 语言库<string.h>
				中的一部分函数。
		
		3.一般来说，SDS 除了保存数据库中的字符串值以外，SDS 还可以作为缓冲区（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。
	2.链表
		链表是一种常用的数据结构，C 语言内部是没有内置这种数据结构的实现，所以Redis自己构建了链表的实现。
		1.链表定义：
			
			typedef struct listNode{
				//前置节点
				struct listNode *prev;
				//后置节点
				struct listNode *next;
				//节点的值
				void *value; 
			}listNode
			

			　　通过多个 listNode 结构就可以组成链表，这是一个双向链表，Redis还提供了操作链表的函数：

			
			typedef struct list{
				//表头节点
				listNode *head;
				//表尾节点
				listNode *tail;
				//链表所包含的节点数量
				unsigned long len;
				//节点值复制函数
				void *(*dup) (void *ptr);
				//节点值释放函数
				void (* free) (void *ptr);
				//节点值对比函数
				int (*match) (void *ptr,void *key);
			}list;
			
		2.链表特性:
			①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。
		　　②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　　
		　　③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。
		　　④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。
	3.字典
		字典是一种用于保存键值对的抽象数据结构。字典中的每一个键 key 都是唯一的，通过 key 可以对值来进行查找或修改。C 语言中没有内置这种数据结构的实现，所以字典依然是 Redis自己构建的。

	　　Redis 的字典使用哈希表作为底层实现。

　　	1.哈希表结构定义：
			
			typedef struct dictht{
				//哈希表数组
				dictEntry **table;
				//哈希表大小
				unsigned long size;
				//哈希表大小掩码，用于计算索引值
				//总是等于 size-1
				unsigned long sizemask;
				//该哈希表已有节点的数量
				unsigned long used;
			}dictht
			
			　　哈希表是由table数组 组成，table 中每个元素都是指向 dictEntry 结构，dictEntry 结构定义如下：
			
			typedef struct dictEntry{
				//键
				void *key;
				//值
				union {
					void *val;
					uint64_tu64;
					int64_ts64;
				}v;
				//指向下一个哈希表节点，形成链表
				struct dictEntry *next;
			}dictEntry
			

　　		key 用来保存键，val 属性用来保存值
			---------------------------------------------------------------
			值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。
		2.常见问题
			①、哈希算法：Redis计算哈希值和索引值方法如下：
			
				#1、使用字典设置的哈希函数，计算键 key 的哈希值
				hash = dict->type->hashFunction(key);
				#2、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值
				index = hash & dict->ht[x].sizemask;
			
		　　②、解决哈希冲突：方法是链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。
		　　③、扩容和收缩：当哈希表保存的键值对太多或者太少时，就要通过
				rehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：
			　　　　1、如果执行扩展操作，每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表。相反如果执行的是收缩操作
					，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。

		　　　　　　2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。
		　　　　　　3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。
		　　④、触发扩容的条件：
		　　　　　　1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。
		　　　　　　2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。
		　　　　	ps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。

		　　⑤、渐近式 rehash
					什么叫渐进式rehash？
					也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。
	4.跳跃表
		跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：
		　　1、由很多层结构组成；
		　　2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；
		　　3、最底层的链表包含了所有的元素；
		　　4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；
		　　5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；
		
		1.跳跃表结构
			Redis中跳跃表节点定义如下：
			
			typedef struct zskiplistNode {
				//层
				struct zskiplistLevel{
					//前进指针
					struct zskiplistNode *forward;
					//跨度
					unsigned int span;
				}level[];
				//后退指针
				struct zskiplistNode *backward;
				//分值 
				double score;
				//成员对象
				robj *obj;
			} zskiplistNode
			
			　　多个跳跃表节点构成一个跳跃表：
			
			typedef struct zskiplist{
				//表头节点和表尾节点
				structz skiplistNode *header, *tail;
				//表中节点的数量
				unsigned long length;
				//表中层数最大的节点的层数
				int level;
			}zskiplist;
			
		2.操作过程:
			①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。
		　　②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正
			面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。
			③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。
	5.整数集合
		整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存不同类型(类型为int16_t、int32_t 或者int64_t) 的整数值，并且保证集合中不会出现重复元素。
		
		1.结构
			
			typedef struct intset{
				//编码方式
				uint32_t encoding;
				//集合包含的元素数量
				uint32_t length;
				//保存元素的数组
				int8_t contents[];
			}intset;
			
			①整数集合的每个元素都是 contents 数组的一个数据项，它们按照从小到大的顺序排列，并且不包含任何重复项。
			②length 属性记录了 contents 数组的大小。
			③需要注意的是虽然 contents 数组声明为 int8_t 类型，但是实际上contents 数组并不保存任何 int8_t 类型的值，其真正类型有 encoding 来决定。
		2.操作
			①、升级
		　　当我们新增的元素类型比原集合元素类型的长度要大时，需要对整数集合进行升级，才能将新元素放入整数集合中。具体步骤：
		　　	1、根据新元素类型，扩展整数集合底层数组的大小，并为新元素分配空间。	　　		
				2、将底层数组现有的所有元素都转成与新元素相同类型的元素，并将转换后的元素放到正确的位置，放置过程中，维持整个元素顺序都是有序的。
			　　3、将新元素添加到整数集合中（保证有序）。

		　　升级能极大地节省内存。
		　　②、降级
			　　整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。
	6.压缩列表
		​	压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。
		
		压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。
		
		1.结构
			列表结构见图。
			
			压缩列表的每个节点构成如下:	　
			①、previous_entry_length：记录压缩列表前一个字节的长度。
			------------------------------------------------------------------------------------------
			previous_entry_ength的长度可能是1个字节或者是5个字节，如果上一个节点的长度小于254，则该节点只需要一个字节就可以表示前一个节点的长度了，如果前一个节点的长度大于等于254，则previouslength的第一个字节为254，后面用四个字节表示当前节点前一个节点的长度。利用此原理即当前节点位置减去上一个节点的长度即得到上一个节点的起始位置，压缩列表可以从尾部向头部遍历。这么做很有效地减少了内存的浪费。
			②、encoding：节点的encoding保存的是节点的content的内容类型以及长度，encoding类型一共有两种，一种字节数组一种是整数，
			-----------------------------------
			encoding区域长度为1字节、2字节或者5字节长。
		　　③、content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。
3.五大数据类型实现原理
	在Redis中，并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，这些对象系统也就是前面说的五大数据类型，每一种数据类型都至少用到了一种数据结构。通过这五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型判断一个对象是否可以执行给定的命令，而且可以针对不同的场景，为对象设置多种不同的数据结构，从而优化对象在不同场景下的使用效率。
	
	1.对象的类型与编码
		Redis使用前面说的五大数据类型来表示键和值，每次在Redis数据库中创建一个键值对时，至少会创建两个对象，一个是键对象，一个是值对象，而Redis中的每个对象都是由 redisObject 结构来表示：
			typedef struct redisObject{
				//类型
				unsigned type:4;
				//编码
				unsigned encoding:4;
				//指向底层数据结构的指针
				void *ptr;
				//引用计数
				int refcount;
				//记录最后一次被程序访问的时间
				unsigned lru:22;
			}robj
		
		①、type属性
			对象的type属性记录了对象的类型，这个类型就是前面讲的五大数据类型。
			可以通过type key命令来判断对象类型。
			------------------------------------------------------------------
			注意：在Redis中，键总是一个字符串对象，而值可以是字符串、列表、集合等对象，所以我们通常说的键为字符串键，表示的是这个键对应的值为字符串对象，我们说一个键为集合键时，表示的是这个键对应的值为集合对象。
		②、encoding属性和*ptr指针
			对象的 ptr 指针指向对象底层的数据结构，而数据结构由 encoding 属性来决定。
			
			而每种类型的对象都至少使用了两种不同的编码。
			
			可以通过  OBJECT ENCODING  key 命令查看值对象的编码。
	2.字符串对象
		字符串是Redis最基本的数据类型，不仅所有key都是字符串类型，其它几种数据类型构成的元素也是字符串。注意字符串的长度不能超过512M。
		
		①、编码
		　　字符串对象的编码可以是int，raw或者embstr。
		　　1、int 编码：保存的是可以用 long 类型表示的整数值。
		　　2、raw 编码：保存长度大于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。
		　　3、embstr 编码：保存长度小于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。
		
			可以看出，int 编码是用来保存整数值，raw编码是用来保存长字符串，而embstr是用来保存短字符串。其实 embstr 编码是专门用来保存短字符串的一种优化编码，raw 和 embstr 的区别：
				embstr与raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读。

　			ps：Redis中对于浮点数类型也是作为字符串保存的，在需要的时候再将其转换成浮点数类型。

		②、编码的转换
		　　当 int 编码保存的值不再是整数，或大小超过了long的范围时，自动转化为raw。
		
		　　对于embstr编码，由于embstr是只读的（Redis 没有对其编写任何的修改程序），
			在对embstr对象进行修改时，都会先转化为raw再进行		修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了44个字节。
	3.列表对象
	　　①、编码
	　　	列表对象的编码可以是 ziplist(压缩列表) 和 linkedlist(双端链表)。 

		②、编码转换
		　　当同时满足下面两个条件时，使用ziplist（压缩列表）编码：
		　　1、列表保存元素个数小于512个
		　　2、每个元素长度小于64字节
		　　不能满足这两个条件的时候使用 linkedlist 编码。
		
			---------------------------------------------------------------------------------
		　　上面两个条件可以在redis.conf 配置文件中的 list-max-ziplist-value选项和 list-max-ziplist-entries 选项进行配置。
	4.哈希对象
		哈希对象的键是一个字符串类型，值是一个键值对集合。

	　　①、编码
			哈希对象的编码可以是 ziplist 或者 hashtable。
		　　当使用ziplist，也就是压缩列表作为底层实现时，新增的键值对是保存到压缩列表的表尾。
			hashtable 编码的哈希对象底层使用字典数据结构，哈希对象中的每个键值对都使用一个字典键值对。

		②、编码转换
		　　和上面列表对象使用 ziplist 编码一样，当同时满足下面两个条件时，使用ziplist（压缩列表）编码：
			　　1、列表保存元素个数小于512个
			　　2、每个元素长度小于64字节
		　　不能满足这两个条件的时候使用 hashtable 编码。第一个条件可以通过配置文件中的 set-max-intset-entries 进行修改。
	5.集合对象
	　　①、编码
		　　集合对象的编码可以是 intset 或者 hashtable。
		
		　　intset 编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合中。
		　　hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，这里的每个字符串对象就是一个集合中的元素	，而字典的值则全部设置为 null。
			--------------------------------------------------------------------------------------------------
			这里可以类比Java集合中HashSet 集合的实现，HashSet 集合是由 HashMap来实现的，集合中的元素就是HashMap 的key，而 HashMap 的值都设为 null。

		②、编码转换
		　　当集合同时满足以下两个条件时，使用 intset 编码：
			　　1、集合对象中所有元素都是整数
			　　2、集合对象所有元素数量不超过512
		　　不能满足这两个条件的就使用 hashtable 编码。第二个条件可以通过配置文件的 set-max-intset-entries 进行配置。
	6.有序集合对象
	　　①、编码
	　　	有序集合的编码可以是 ziplist 或者 skiplist。
			1.ziplist编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列，小的放置在靠近表头的位置，大的放置在靠近表尾的位置。

			2.skiplist 编码的有序集合对象使用 zset 结构作为底层实现，一个 zset 结构同时包含一个字典和一个跳跃表
			字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。
	　　	这两种数据结构会通过指针来共享相同元素的成员和分值，所以不会产生重复成员和分值，造成内存的浪费。
			说明：其实有序集合单独使用字典或跳跃表其中一种数据结构都可以实现，但是这里使用两种数据结构组合起来，原因是假如我们单独使用字典，虽然能以O(1)的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以每次进行范围操作的时候都要进行排序；假如我们单独使用跳跃表来实现，虽然能执行范围操作，但是查找操作由O(1)的复杂度变为了O(logN)。因此Redis使用了两种数据结构来共同实现有序集合。

	　　②、编码转换
	　　	当有序集合对象同时满足以下两个条件时，对象使用 ziplist 编码：
		　　	1、保存的元素数量小于128；
		　　	2、保存的所有元素长度都小于64字节。
	　　	不能满足上面两个条件的使用 skiplist 编码。以上两个条件也可以通过Redis配置文件zset-max-ziplist-entries 选项和 	
			zset-max-ziplist-value 进行修改。
	7.内存回收和内存共享
		①、内存回收
	　		前面讲 Redis 的每个对象都是由 redisObject 结构表示：
			其中关键的 type属性，encoding 属性和 ptr 指针都介绍过了，那么 refcount 属性是干什么的呢？
		　　因为 C 语言不具备自动回收内存功能，那么该如何回收内存呢？于是 Redis自己构建了一个内存回收机制，通过在 redisObject 
			结构中的 refcount 属性实现。这个属性会随着对象的使用状态而不断变化：
			　　1、创建一个新对象，属性 refcount 初始化为1
				2、对象被一个新程序使用，属性 refcount 加 1
				3、对象不再被一个程序使用，属性 refcount 减 1
				4、当对象的引用计数值变为 0 时，对象所占用的内存就会被释放。
			但是会存在循环引用的情况，这里就要考虑到内存淘汰策略，见后面。
			
		②、内存共享 
　　		refcount 属性除了能实现内存回收以外，还能用于内存共享。
　　		比如通过如下命令 set k1 100,创建一个键为 k1，值为100的字符串对象，接着通过如下命令 set k2 100 ，创建一个键为 	
			k2，值为100 的字符串对象，那么 Redis 是如何做的呢？
				1、将数据库键的值指针指向一个现有值的对象
				2、将被共享的值对象引用refcount 加 1
			注意：Redis的共享对象目前只支持整数值的字符串对象。之所以如此，实际上是对内存和CPU（时间）的平衡：共享对象虽然会降低内存消耗，但是判断两个对象是否相等却需要消耗额外的时间。对于整数值，判断操作复杂度为O(1)；对于普通字符串，判断复杂度为O(n)；而对于哈希、列表、集合和有序集合，判断的复杂度为O(n^2)。
			
			虽然共享对象只能是整数值的字符串对象，但是5种类型都可能使用共享对象（如哈希、列表等的元素可以使用）。
	8.对象的空转时间
		在redisObject结构中，前面介绍了type、encoding、ptr和refcount属性，最后一个lru属性，该属性记录了对象最后一次被命令程序访问的时间。

	　　使用 OBJECT IDLETIME 命令可以打印给定键的空转时长，通过将当前时间减去值对象的 lru 时间计算得到。
		lru属性除了计算空转时长以外，还可以配合前面内存回收配置使用。如果Redis打开了maxmemory选项，且内存回收算法选择的是volatile-lru或allkeys—lru，那么当Redis内存占用超过maxmemory指定的值时，Redis会优先选择空转时间最长的对象进行释放。
4.RDB持久化
	由于Redis是一个内存数据库，所谓内存数据库，就是将数据库中的内容保存在内存中，
	--------------------------------------------------------------------------------------------
	这与传统的MySQL，Oracle等关系型数据库直接将内容保存到硬盘中相比，内存数据库的读写效率比传统数据库要快的多（内存的读写效率远远大于硬盘的读写效率）。但是保存在内存中也随之带来了一个缺点，一旦断电或者宕机，那么内存数据库中的数据将会全部丢失。

　　为了解决这个缺点，Redis提供了将内存数据持久化到硬盘，以及用持久化文件来恢复数据库数据的功能。Redis 	
	支持两种形式的持久化，一种是RDB快照（snapshotting），另外一种是AOF（append-only-file）。	
	 
	1.简介
		RDB是Redis用来进行持久化的一种方式，是把当前内存中的数据集快照写入磁盘，是数据库中所有键值对数据（也就是 Snapshot 快照）。恢复时是将快照文件直接读到内存里。
	2.触发方式
		1.自动触发
			在配置文件中(redis.conf 配置文件中的 SNAPSHOTTING 下)。
			
			save：这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。
		2.手动触发
			手动触发Redis进行RDB持久化的命令有两种：
			　　1、save
			　　该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。
			　　显然该命令对于内存比较大的实例会造成长时间阻塞，这是致命的缺陷，为了解决此问题，Redis提供了第二种方式。
				--------------------------------------------------------------------------
				(rdbcompression:默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大 )。
			
			　　2、bgsave
				执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体操作是Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。

			　　基本上 Redis 内部所有的RDB操作都是采用 bgsave 命令。
				-----------------------------------------------------------------
			　　ps:执行执行 flushall 命令，也会产生dump.rdb文件，但里面是空的.
			
	----------------------------------------------------------------------
	3.恢复数据
		将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可，redis就会自动加载文件数据至内存了。Redis 服务器在载入 RDB 文件期间，会一直处于阻塞状态，直到载入工作完成为止。
		
	4.停止RDB持久化
		有些情况下，我们只想利用Redis的缓存功能，并不像使用 Redis 的持久化功能，那么这时候我们最好停掉 RDB 持久化。
		
			1.可以通过上面讲的在配置文件 redis.conf 中，可以注释掉所有的 save 行来停用保存功能或者直接一个空字符串来实现停用：save ""
			2.也可以通过命令：redis-cli config set save " "
	
	5.RDB的优势和劣势
		​①、优势
		　　1.RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集。这种文件非常适合用于进行备份和灾难恢复。
		　　2.生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。
		　　3.RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

	　　②、劣势
			1、RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，如果不采用压缩算法，频繁执行成本过高(影响性能)(内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑)，——(下面评论说这句话是错误的，实际上用的是copy-on-write的机制，实际上是fork（）的子进程引用了数据的地址，只有数据被修改的时候才会进行拷贝修改指针引用，消耗还是可以接受的)
		　　2、RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问
			(版本不兼容)
		　　3、在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改(数据有丢失)
	6.RDB自动保存原理
		Redis有个服务器状态结构：
		
		struct redisService{
			//1、记录保存save条件的数组
			struct saveparam *saveparams;
			//2、修改计数器
			long long dirty;
			//3、上一次执行保存的时间
			time_t lastsave;
		}
		
		①、首先看记录保存save条件的数组 saveparams，里面每个元素都是一个 saveparam 结构：

		
		struct saveparam{
			//秒数
			time_t seconds;
			//修改数 
			int changes;
		};
		
		
		②、dirty 计数器和lastsave 属性
		
		dirty 计数器记录距离上一次成功执行 save 命令或者 bgsave 命令之后，Redis服务器进行了多少次修改（包括写入、删除、更新等操作）。

　　	lastsave 属性是一个时间戳，记录上一次成功执行 save 命令或者 bgsave 命令的时间。

　　	通过这两个命令，当服务器成功执行一次修改操作，那么dirty 计数器就会加 1，而lastsave
 		属性记录上一次执行save或bgsave的时间，Redis 服务器还有一个周期性操作函数 severCron ,默认每隔 100 毫秒就会执行一次，该函数会遍历并检查 saveparams 数组中的所有保存条件，只要有一个条件被满足，那么就会执行 bgsave 命令。

　　	执行完成之后，dirty 计数器更新为 0 ，lastsave 也更新为执行命令的完成时间。

5.AOF持久化
	RDB持久化存在一个缺点是一定时间内做一次备份，如果redis意外down掉的话，就会丢失最后一次快照后的所有修改(数据有丢失)。对于数据完整性要求很严格的需求，怎么解决呢？

　　来看看Redis的另一种持久化方式——AOF。

	1.简介
		Redis的持久化方式之一RDB是通过保存数据库中的键值对来记录数据库的状态。而另一种持久化方式 AOF 则是通过保存Redis服务器所执行的写命令来记录数据库状态。
	2.AOF配置
		在 redis.conf 配置文件的 APPEND ONLY MODE 下：
			1.appendonly：默认值为no，也就是说redis 默认使用的是rdb方式持久化，如果想要开启 AOF 持久化方式，需要将 appendonly 修改为 yes。
			2.appendfsync：aof持久化策略的配置；
	　　　　　　no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全；
	　　　　　　always表示每次写入都执行fsync，以保证数据同步到磁盘，效率很低；
	　　　　　　everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。通常选择 everysec ，兼顾安全性和效率。
	
			--------------------------------------------------------------------------------------------------------------
			3.auto-aof-rewrite-percentage：默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。
　			4.auto-aof-rewrite-min-size：64mb。设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。
	-------------------------------------------------------------------------------
	3.开启AOF
		将 redis.conf 的 appendonly 配置改为 yes 即可。
	4.AOF文件恢复
		重启 Redis 之后就会进行 AOF 文件的载入。
	　　异常修复命令：redis-check-aof --fix 进行修复
	----------------------------------------------------------------------------------------
	5.AOF重写
		由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的进行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof 来重写。
		也就是说AOF文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。

 　		AOF文件重写触发机制：通过 redis.conf 配置文件中的 	
		auto-aof-rewrite-percentage：默认值为100，以及auto-aof-rewrite-min-size：64mb 配置，也就是说Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。

　　	这里再提一下，我们知道 Redis 是单线程工作，如果重写 AOF 需要比较长的时间，那么在重写 AOF 	
		期间，Redis将长时间无法处理其他的命令，这显然是不能忍受的。Redis为了克服这个问题，解决办法是将 AOF 重写程序放到子程序中进行，这样有两个好处：
	　　	①、子进程进行 AOF 重写期间，服务器进程（父进程）可以继续处理其他命令。
　　		②、子进程带有父进程的数据副本，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性。

　　	使用子进程解决了上面的问题，但是新问题也产生了：因为子进程在进行 AOF 
		重写期间，服务器进程依然在处理其它命令，这新的命令有可能也对数据库进行了修改操作，使得当前数据库状态和重写后的 AOF 文件状态不一致。

　　	为了解决这个数据状态不一致的问题，Redis 服务器设置了一个 AOF 	
		重写缓冲区，这个缓冲区是在创建子进程后开始使用，当Redis服务器执行一个写命令之后，就会将这个写命令也发送到 AOF 重写缓冲区。当子进程完成 AOF 重写之后，就会给父进程发送一个信号，父进程接收此信号后，就会调用函数将 AOF 重写缓冲区的内容都写到新的 AOF 文件中。

　　	这样将 AOF 重写对服务器造成的影响降到了最低。
	6.AOF的优缺点
		​1.优点：
		　　①、AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。
		　　②、AOF 文件使用 Redis 命令追加的形式来构造，因此，即使 Redis 只能向 AOF 文件写入命令的片断，使用 redis-check-aof 	
			工具也很容易修正 AOF 文件。
		　　③、AOF 文件的格式可读性较强，这也为使用者提供了更灵活的处理方式。例如，如果我们不小心错用了 FLUSHALL 
			命令，在重写还没进行时，我们可以手工将最后的 FLUSHALL 命令去掉，然后再使用 AOF 来恢复数据。

	　　2.缺点：
	　	　	①、对于具有相同数据的的 Redis，AOF 文件通常会比 RDB 文件体积更大。
	　　	②、虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。但在 Redis 的负载较高时，RDB 比 
			AOF 具有更好的性能保证。
	　　	③、RDB 使用快照的形式来持久化整个 Redis 数据，而 AOF 只是将每次执行的命令追加到 AOF 文件中，因此从理论上说，RDB 比 	
			AOF 方式更健壮。官方文档也指出，AOF 的确也存在一些 BUG，这些 BUG 在 RDB 没有存在。

	 　	3.那么对于 AOF 和 RDB 两种持久化方式，我们应该如何选择呢？

		　　如果可以忍受一小段时间内数据的丢失，毫无疑问使用 RDB 是最好的，定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 
			并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，而且使用 RDB 还可以避免 AOF 一些隐藏的 bug；否则就使用 AOF 重写。但是一般情况下建议不要单独使用某一种持久化机制，而是应该两种一起用，在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。
			------------------------------------------------------------------------------------------
			Redis后期官方可能都有将两种持久化方式整合为一种持久化模型。
	7.RDB-AOF混合持久化
		​在Redis4.0之后，又新增了RDB-AOF混合持久化方式。

　　	这种方式结合了RDB和AOF的优点，既能快速加载又能避免丢失过多的数据。

	　　	具体配置为：aof-use-rdb-preamble，设置为yes表示开启，设置为no表示禁用。
			当开启混合持久化时，主进程先fork出子进程将现有内存副本全量以RDB方式写入aof文件中，然后将缓冲区中的增量命令以AOF方式写入aof文件中，写入完成后通知主进程更新相关信息，并将新的含有 RDB和AOF两种格式的aof文件替换旧的aof文件。	

	　　	简单来说：混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。

　　	这种方式优点我们很好理解，缺点就是不能兼容Redis4.0之前版本的备份文件了。
6.主从复制
	前面介绍Redis，我们都在一台服务器上进行操作的，也就是说读和写以及备份操作都是在一台Redis服务器上进行的，那么随着项目访问量的增加，对Redis服务器的操作也越加频繁，虽然Redis读写速度都很快，但是一定程度上也会造成一定的延时，那么为了解决访问量大的问题，通常会采取的一种方式是主从架构Master/Slave，Master 以写为主，Slave 以读为主，Master 主节点更新后根据配置，自动同步到从机Slave 节点。
	
	1.主从关系
		​①、增量复制
　　		主节点执行写命令，从节点可以读到
		②、全量复制
			当执行SLAVEOF命令之后，主节点以前的一些key，从节点也会复制过来
		③、主从读写分离
　　		从节点不能执行写命令，可以在配置文件中修改slave-read-only,修改为 no 	
			之后，执行写命令是可以的。但是从节点写命令的数据其他从节点或者主节点都不能获取的。
		④、主节点宕机
			主节点 Master 挂掉之后，从节点角色还是不会改变的。
		⑤、主节点宕机后恢复
			主节点Master挂掉之后，马上启动主机Master，又恢复了主节点的角色。
	
	2.主从复制原理
		Redis的复制功能分为同步（sync）和命令传播（command propagate）两个操作。
		
		①、旧版同步
	　　	当从节点发出 SLAVEOF 命令，要求从服务器复制主服务器时，从服务器通过向主服务器发送 SYNC 命令来完成。该命令执行步骤：
	　　		1、从服务器向主服务器发送 SYNC 命令
			　　2、收到 SYNC 命令的主服务器执行 BGSAVE 命令，在后台生成一个 RDB 文件，并使用一个缓冲区记录从开始执行的所有写命令
			　　3、当主服务器的 BGSAVE 命令执行完毕时，主服务器会将 BGSAVE 命令生成的 RDB 文件发送给从服务器，从服务器接收此 
				RDB文件，并将服务器状态更新为RDB文件记录的状态。
	　　		4、主服务器将缓冲区的所有写命令也发送给从服务器，从服务器执行相应命令。

　　	②、命令传播
		　　当同步操作完成之后，主服务器会进行相应的修改命令，这时候从服务器和主服务器状态就会不一致。

		　　为了让主服务器和从服务器保持状态一致，主服务器需要对从服务器执行命令传播操作，主服务器会将自己的写命令发送给从服务器执
			行。从服务器执行相应的命令之后，主从服务器状态继续保持一致。

　　		总结：通过同步操作以及命令传播功能，能够很好的保证了主从一致的特性。
		但是我们考虑一个问题，如果从服务器在同步主服务器期间，突然断开了连接，而这时候主服务器进行了一些写操作，这时候从服务器恢复连接，如果我们在进行同步，那么就必须将主服务器从新生成一个RDB文件，然后给从服务器加载，这样虽然能够保证一致性，但是其实断开连接之前主从服务器状态是保持一致的，不一致的是从服务器断开连接，而主服务器执行了一些写命令，那么从服务器恢复连接后能不能只要断开连接的哪些写命令，而不是整个RDB快照呢？
		同步操作其实是一个非常耗时的操作，主服务器需要先通过BGSAVE命令来生成一个RDB文件，然后需要将该文件发送给从服务器，从服务器接收该文件之后，接着加载该文件，并且加载期间，从服务器是无法处理其他命令的。

		为了解决这个问题，Redis从2.8版本之后，使用了新的同步命令 PSYNC 来代替 SYNC 命令。该命令的部分重同步功能用于处理断线后重复制的效率问题。也就是说当从服务器在断线后重新连接主服务器时，主服务器只将断开连接后执行的写命令发送给从服务器，从服务器只需要接收并执行这些写命令即可保持主从一致。
		
	3.主从复制的缺点
		主从复制由于所有的写操作都是在 Master 节点上操作，然后同步到 Slave 节点，那么同步就会有一定的延时，当系统很繁忙的时候，延时问题就会更加严重，而且会随着从节点slave的增多而愈加严重。
7.哨兵模式详解
	1.哨兵模式
		通过前面的配置，主节点Master只有一个，一旦主节点挂掉之后，从节点没法担起主节点的任务，那么整个系统也无法运行。如果主节点挂掉之后，从节点能够自动变成主节点，那么问题就解决了，于是哨兵模式诞生了。　		
		哨兵模式就是不时地监控redis是否按照预期良好地运行（至少是保证主节点是存在的），若一台主机出现问题时，哨兵会自动将该主机下的某一个从机设置为新的主机，并让其他从机和新主机建立主从关系。
		--------------------------------------------------------------------------
		哨兵模式也存在单点故障问题，如果哨兵机器挂了，那么就无法进行监控了，解决办法是哨兵也建立集群，Redis哨兵模式是支持集群的。
	
	2.哨兵模式工作原理
		①、三个定时任务
		　　一.每10秒每个 sentinel 对master 和 slave 执行info 命令:该命令一是用来发现slave节点,二是确定主从关系.
		　　二.每2秒每个 sentinel 通过 master 节点的 channel(名称为_sentinel_:hello) 
			交换信息(pub/sub):用来交互对节点的看法(后面会介绍的节点主观下线和客观下线)以及自身信息.
		　　三.每1秒每个 sentinel 对其他 sentinel 和 redis 执行 ping 命令,用于心跳检测,作为节点存活的判断依据.

　　	②、主观下线和客观下线

		　　一.主观下线
		　　SDOWN:subjectively down,直接翻译的为”主观”失效,即当前sentinel实例认为某个redis服务为”不可用”状态.
		　　二.客观下线
		　　ODOWN:objectivelydown,直接翻译为”客观”失效,即多个sentinel实例都认为master处于”SDOWN”状态,那么此时master将处于ODOWN,ODO
			WN可以简单理解为master已经被集群确定为”不可用”,将会开启故障转移机制.
			
		③、故障转移

		　　故障转移是由 sentinel 领导者节点来完成的(只需要一个sentinel节点),关于 sentinel 领导者节点的选取也是每个 
			sentinel向其他 sentinel 节点发送我要成为领导者的命令,超过半数sentinel 节点同意,并且也大于quorum ,那么他将成为领导者,如果有多个sentinel都成为了领导者,则会过段时间在进行选举.

		　　sentinel 领导者节点选举出来后,会通过如下几步进行故障转移:

			　　一.从 slave 节点中选出一个合适的 节点作为新的master节点.这里的合适包括如下几点:
			　　　　1.选择 slave-priority(slave节点优先级)最高的slave节点,如果存在则返回,不存在则继续下一步判断.
			　　　　2.选择复制偏移量最大的 slave 节点(复制的最完整),如果存在则返回,不存在则继续.
			　　　　3.选择runId最小的slave节点(启动最早的节点)
			　　二.对上面选出来的 slave 节点执行 slaveof no one 命令让其成为新的 master 节点.
			　　三.向剩余的 slave 节点发送命令,让他们成为新master 节点的 slave 节点,复制规则和前面设置的 parallel-syncs 参数有关.
			　　四.更新原来master节点配置为slave节点,并保持对其进行关注,一旦这个节点重新恢复正常后,会命令它去复制新的master节点信q
				息.(注意:原来的master节点恢复后是作为slave的角色)

			-------------------------------------------------------------------------------------------
		　　可以从 sentinel 日志中出现的几个消息来进行查看故障转移:
			　　1.+switch-master:表示切换主节点(从节点晋升为主节点)
			　　2.+sdown:主观下线
			　　3.+odown:客观下线
			　　4.+convert-to-slave:切换从节点(原主节点降为从节点)
8.集群模式详解
	1.为什么需要集群？
		​①、并发量
			通常来说,单台Redis能够执行10万/秒的命令,这个并发基本上能够满足我们所有需求了,(但有时候比如做离线计算,为了更快的得出结果),有时候我们希望超过这个并发,那这个时候单机就不满足我们需求了,就需要集群了.
　　	②、数据量
			(通常来说,单台服务器的内存大概在16G-256G之间,前面)我们说Redis数据量都是存在内存中的,那如果实际业务要保存在Redis的数据量超过了单台机器的内存,这个时候最简单的方法是增加服务器内存,但是单台服务器内存不可能无限制的增加,纵向扩展不了了,便想到如何进行横向扩展.这时候我们就会想将这些业务数据分散存储在多台Redis服务器中,但是要保证多台Redis服务器能够无障碍的进行内存数据沟通,这也就是Redis集群.
	2.数据分区方式
		对于集群来说,如何将原来单台机器上的数据拆分,然后尽量均匀的分布到多台机器上,这是我们创建集群首先要考虑的一个问题,通常来说,有如下两种数据分区方式.
		　　①、顺序分布
		　　	比如我们有100W条数据,有3台服务器,我们可以将100W/3的结果分别存储到三台服务器上。
		
				特点：键值业务相关；数据分散，但是容易造成访问倾斜；支持顺序访问；支持批量操作
		　	②、哈希分布
				同样是100W条数据,有3台服务器,通过自定义一个哈希函数,比如节点取余的方法,余数为0的存在第一台服务器,余数为1的存在第二台服务器,余数为2的存储在第三台服务器.
				
				特点：数据分散度高；键值分布与业务无关；不支持顺序访问；支持批量操作。
	3.一致性哈希分布
		对于上面介绍的哈希分布,如果向集群中增加节点，或者集群中有节点宕机，这个时候会发生大量的数据迁移。
		
		那么如何使得集群中新增节点或者删除节点时，数据迁移量最少？——一致性哈希算法诞生。	
			假设有一个哈希环，从0到2的32次方，均匀的分成三份，中间存放三个节点，沿着顺时针旋转，从Node1到Node2之间的数据，存放在Node2节点上；从Node2到Node3之间的数据，存放在Node3节点上，依次类推。

		　　假设Node1节点宕机，那么原来Node3到Node1之间的数据这时候改为存放到Node2节点上，Node2到Node3之间数据保持不变，原来Node1
			到Node2之间的数据还是存放在Node2上，也就是只影响三分之一的数据，节点越多，影响数据越少。

			同理，假设增加一个节点，影响的数据甚至更少。

			当然，实际业务中并不是你节点均匀分布，访问就会很平均，这时候容易造成访问倾斜的问题，这里就会引出虚拟节点的定义。
	4.Redis Cluster虚拟槽分区
		Redis集群数据分布没有使用一致性哈希分布，而是使用虚拟槽分区概念。

	　　Redis内部内置了序号0-16383个槽位，每个槽位可以用来存储一个数据集合，将这些槽位按顺序分配到集群中的各个节点。每次新的数据到
		来，会通过哈希函数 CRC16(key) 算出将要存储的槽位下标，然后通过该下标找到前面分配的Redis节点，最后将数据存储到该节点中。

		至于为什么Redis不使用一致性哈希分布，而是虚拟槽分区。因为虚拟槽分区虽然没有一致性哈希那么灵活，但是CRC16(key)%16384 已经分布很均匀了，并且对于后面节点增删操作起来也很方便。
		
		
9.过期删除策略和内存淘汰策略
	1.设置Redis键过期时间
		Redis提供了四个命令来设置过期时间（生存时间）。
		　　①、EXPIRE < key> < ttl> ：表示将键 key 的生存时间设置为 ttl 秒。
		　　②、PEXPIRE < key> < ttl> ：表示将键 key 的生存时间设置为 ttl 毫秒。
		　　③、EXPIREAT < key> < timestamp> ：表示将键 key 的生存时间设置为 timestamp 所指定的秒数时间戳。
		　　④、PEXPIREAT < key> < timestamp> ：表示将键 key 的生存时间设置为 timestamp 所指定的毫秒数时间戳。
	　　PS：在Redis内部实现中，前面三个设置过期时间的命令最后都会转换成最后一个PEXPIREAT 命令来完成。

	　　另外补充两个知识点：
		　　一、移除键的过期时间
		　　PERSIST < key> ：表示将key的过期时间移除。
		　　二、返回键的剩余生存时间
		　　TTL < key> ：以秒的单位返回键 key 的剩余生存时间。
		　　PTTL < key> ：以毫秒的单位返回键 key 的剩余生存时间。
	2.Redis过期时间的判定
		在Redis内部，每当我们设置一个键的过期时间时，Redis就会将该键带上过期时间存放到一个过期字典中。当我们查询一个键时，Redis便首先检查该键是否存在过期字典中，如果存在，那就获取其过期时间。然后将过期时间和当前系统时间进行比对，比系统时间大，那就没有过期；反之判定该键过期。
	3.过期删除策略
		 ①、定时删除
		　　在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。
		　　优点：定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。
		　　缺点：对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 时间，对服务器的响应时间和吞吐量造成影响。

		 ②、惰性删除
		　　设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。
		　　优点：对 CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。
		　　缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中，如果数据库中有很多这种使用不到的		过期键，这些键便永远不会被删除，内存永远不会释放。从而造成内存泄漏。

		 ③、定期删除
		　　每隔一段时间，我们就对一些key进行检查，删除里面过期的key。
		　　优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。
		　　缺点：1.难以确定删除操作执行的时长和频率。
		　　　　　2.如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。
		　　　　　3.如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。					 
					4.另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。
	4.Redis过期删除策略
		单一使用某一策略都不能满足实际需求，那就组合来使用吧。
		
		Redis的过期删除策略就是：惰性删除和定期删除两种策略配合使用。

	　　	惰性删除：Redis的惰性删除策略(由 db.c/expireIfNeeded 函数实现)，是所有键读写命令执行之前都会调用 expireIfNeeded 	
			函数对其进行检查，如果过期，则删除该键，然后执行键不存在的操作；未过期则不作操作，继续执行原有的命令。

		　　定期删除：由redis.c/activeExpireCycle 
			函数实现，函数以一定的频率运行，每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键。

			---------------------------------------------------------------------------------------
　		　	注意：并不是一次运行就检查所有的库，所有的键，而是随机检查一定数量的键。
			定期删除函数的运行频率，在Redis2.6版本中，规定每秒运行10次，大概100ms运行一次。在Redis2.8版本后，可以通过修改配置文件redis.conf 的 hz 选项来调整这个次数。
		 我们看到，通过过期删除策略，对于某些永远使用不到的键，并且多次定期删除也没选定到并删除，那么这些键同样会一直驻留在内存中，又或者在Redis中存入了大量的键，这些操作可能会导致Redis内存不够用，这时候就需要Redis的内存淘汰策略了。
	5.内存淘汰策略
		 ①、设置Redis最大内存
	　　	在配置文件redis.conf 中，可以通过参数 maxmemory < bytes> 来设定最大内存：
			不设定该参数默认是无限制的，但是通常会设定其为物理内存的四分之三。

		②、设置内存淘汰方式
　　		当现有内存大于 maxmemory 时，便会触发redis主动淘汰内存方式，通过设置 maxmemory-policy ，有如下几种淘汰方式：
			　　1）volatile-lru  利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used ) 。
			　　2）allkeys-lru利用LRU算法移除任何key（和上一个相比，删除的key包括设置过期时间和不设置过期时间的）。通常使用该方式.
			　　3）volatile-random 移除设置过过期时间的随机key 。
			　　4）allkeys-random 无差别的随机移除。
			　　5）volatile-ttl  移除即将过期的key(minor TTL) 
			　　6）noeviction 不移除任何key，只是返回一个写错误 ，默认选项，一般不会选用。
　　		在redis.conf 配置文件中，可以设置淘汰方式。
	
	6.总结
	　	Redis过期删除策略是采用惰性删除和定期删除这两种方式组合进行的，惰性删除能够保证过期的数据我们在获取时一定获取不到，而定	
		期删除设置合适的频率，则可以保证无效的数据及时得到释放，而不会一直占用内存数据。		
		但是我们说Redis是部署在物理机上的，内存不可能无限扩充的，当内存达到我们设定的界限后，便自动触发Redis内存淘汰策略，而具体的策略方式要根据实际业务情况进行选取。
10.缓存穿透、缓存击穿、缓存雪崩
		我们来看看Redis使用过程中需要注意的三种问题：缓存穿透、缓存击穿、缓存雪崩。
		1.缓存穿透
			1.概念: 缓存穿透：缓存和数据库中都没有的数据，可用户还是源源不断的发起请求，导致每次请求都会到数据库，从而压垮数据库。
			2.解决办法
				①、业务层校验
				　　用户发过来的请求，根据请求参数进行校验，对于明显错误的参数，直接拦截返回。
				　　比如，请求参数为主键自增id，那么对于请求小于0的id参数，明显不符合，可以直接返回错误请求。
				②、不存在数据设置短过期时间
				　　对于某个查询为空的数据，可以将这个空结果进行Redis缓存，但是设置很短的过期时间，比如30s，可以根据实际业务设定。注意一定不要影响正常业务。
				③、布隆过滤器
				　　布隆过滤器是一种数据结构，利用极小的内存，可以判断大量的数据“一定不存在或者可能存在”。
				
				　　对于缓存穿透，我们可以将查询的数据条件都哈希到一个足够大的布隆过滤器中，用户发送的请求会先被布隆过滤器拦截，一
					定不存在的数据就直接拦截返回了，从而避免下一步对数据库的压力。
		2.缓存击穿
			1.概念:　缓存击穿：Redis中一个热点key在失效的同时，大量的请求过来，从而会全部到达数据库，压垮数据库。(要注意的是这是某一个热点key过期失效，和后面介绍缓存雪崩是有区别的)
			2.解决办法:
				①、设置热点数据永不过期
					对于某个需要频繁获取的信息，缓存在Redis中，并设置其永不过期。当然这种方式比较粗暴，对于某些业务场景是不适合的.
　　			②、定时更新
　　				比如这个热点数据的过期时间是1h，那么每到59minutes时，通过定时任务去更新这个热点key，并重新设置其过期时间。

　　			③、互斥锁
　　				这是解决缓存击穿比较常用的方法。
				　　互斥锁简单来说就是在Redis中根据key获得的value值为空时，先锁上，然后从数据库加载，加载完毕，释放锁。若其他线程	也在请求该key时，发现获取锁失败，则睡眠一段时间（比如100ms）后重试。
		3.缓存雪崩
			1.概念:缓存雪崩：Redis中缓存的数据大面积同时失效，或者Redis宕机，从而会导致大量请求直接到数据库，压垮数据库。
			2.解决办法:
				①、设置有效期均匀分布
			　　	避免缓存设置相近的有效期，我们可以在设置有效期时增加随机值；
			　　	或者统一规划有效期，使得过期时间均匀分布。
			　　②、数据预热
			　　	对于即将来临的大量请求，我们可以提前走一遍系统，将数据提前缓存在Redis中，并设置不同的过期时间。
			　　③、保证Redis服务高可用
			　　	前面我们介绍过Redis的哨兵模式和集群模式，为防止Redis集群单节点故障，可以通过这两种模式实现高可用。
		
11.redis和数据库的缓存一致性

	首先先来了解下一致性，在分布式系统中，一致性是指多副本问题中的数据一致性。一致性可以分为强一致性、弱一致性和最终一致性

		a.强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。强一致性对用户比较友好，但对系统性能影响比较大。
		b.弱一致性：系统并不保证后续进程或者线程的访问都会返回最新的更新过的值。
		c.最终一致性：也是弱一致性的一种特殊形式，系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。
	大多数系统都是采用的最终一致性，最终一致性是指系统中所有的副本经过一段时间的异步同步之后，最终能够达到一个一致性的状态，也就是说在数据的一致性上存在一个短暂的延迟。


	三种更新策略：
		1.先更新数据库，再更新缓存
		2.先删除缓存，再更新数据库
		3.先更新数据库，再删除缓存
	1.先更新数据库，再更新缓存
		这套方案，大家是普遍反对的。为什么呢？有如下两点原因。

		原因一（线程安全角度）
			同时有请求A和请求B进行更新操作，那么会出现

			（1）线程A更新了数据库
			（2）线程B更新了数据库
			（3）线程B更新了缓存
			（4）线程A更新了缓存

			这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
			
		原因二（业务场景角度）
			有如下两点：
			（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
			2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

			接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。

	2、先删缓存，再更新数据库
		该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

			（1）请求A进行写操作，删除缓存
			（2）请求B查询发现缓存不存在
			（3）请求B去数据库查询得到旧值
			（4）请求B将旧值写入缓存
			（5）请求A将新值写入数据库

		上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

		那么，如何解决呢？采用延时双删策略

		转化为中文描述就是
			（1）先淘汰缓存
			（2）再写数据库（这两步和原来一样）
			（3）休眠1秒，再次淘汰缓存

		这么做，可以将1秒内所造成的缓存脏数据，再次删除。

		那么，这个1秒怎么确定的，具体该休眠多久呢？
		针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

		如果你用了mysql的读写分离架构怎么办？

		ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。
			（1）请求A进行写操作，删除缓存
			（2）请求A将数据写入数据库了
			（3）请求B查询缓存发现，缓存没有值
			（4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
			（5）请求B将旧值写入缓存
			（6）数据库完成主从同步，从库变为新值
		上述情形，就是数据不一致的原因。还是使用双删延时策略，只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

		采用这种同步淘汰策略，吞吐量降低怎么办？

		ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

		第二次删除，如果删除失败怎么办？
		这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：
			（1）请求A进行写操作，删除缓存
			（2）请求B查询发现缓存不存在
			（3）请求B去数据库查询得到旧值
			（4）请求B将旧值写入缓存
			（5）请求A将新值写入数据库
			（6）请求A试图去删除请求B写入对缓存值，结果失败了。
		ok，这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。


		如何解决呢？

		具体解决方案，且看第(3)种更新策略的解析。

	3、先更新数据库，再删缓存(常用的)
		知名社交网站facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。

		这种情况不存在并发问题么？

		不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生
			（1）缓存刚好失效
			（2）请求A查询数据库，得一个旧值
			（3）请求B将新值写入数据库
			（4）请求B删除缓存
			（5）请求A将查到的旧值写入缓存
		ok，如果发生上述情况，确实是会发生脏数据。

		然而，发生这种情况的概率又有多少呢？
		发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。

		假设，有人非要抬杠，有强迫症，一定要解决怎么办？

		如何解决上述并发问题？

		首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。

		还有其他造成不一致的原因么？
		有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。

		如何解决？

		提供一个保障的重试机制即可，这里给出两套方案。

		方案一：

		流程如下所示
			（1）更新数据库数据；
			（2）缓存因为种种问题删除失败
			（3）将需要删除的key发送至消息队列
			（4）自己消费消息，获得需要删除的key
			（5）继续重试删除操作，直到成功
		然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。

		方案二：

		流程如下图所示：
			（1）更新数据库数据
			（2）数据库会将操作信息写入binlog日志当中
			（3）订阅程序提取出所需要的数据以及key
			（4）另起一段非业务代码，获得该信息
			（5）尝试删除缓存操作，发现删除失败
			（6）将这些信息发送至消息队列
			（7）重新从消息队列中获得该数据，重试操作。
		备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。至于oracle中，博主目前不知道有没有现成中间件可以使用。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。
12.3种常见的缓存读写策略
	这3种缓存读写策略各有优劣，不存在最佳，需要我们根据具体的业务场景选择更适合的。
	1.Cache Aside Pattern（旁路缓存模式）
		Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。

		Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是以 DB 的结果为准。

		下面我们来看一下这个策略模式下的缓存读写步骤。

		写 ：
			a.先更新 DB
			b.然后直接删除 cache 。
		读 :
			a.从 cache 中读取数据，读取到就直接返回
			b.cache中读取不到的话，就从 DB 中读取数据返回
			c.再把数据放到 cache 中。
		
		现在我们再来分析一下 Cache Aside Pattern 的缺陷。

		缺陷1：首次请求数据一定不在 cache 的问题

		解决办法：可以将热点数据可以提前放入cache 中。

		缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。

		解决办法：

			a.数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
			b.可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。
	2.Read/Write Through Pattern（读写穿透）
		Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。
		这种缓存读写策略小伙伴们应该也发现了在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入DB的功能。

		写（Write Through）：
			a.先查 cache，cache 中不存在，直接更新 DB。
			b.cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。
		读(Read Through)：
			a.从 cache 中读取数据，读取到就直接返回 。
			b.读取不到的话，先从 DB 加载，写入到 cache 后返回响应。
			
		Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read-Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。

		和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。
	3.Write Behind Pattern（异步缓存写入）
		Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

		但是，两个又有很大的不同：Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。
		很明显，这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没异步更新DB的话，cache服务可能就就挂掉了。
		这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 InnoDB Buffer Pool 机制都用到了这种策略。

		Write Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。