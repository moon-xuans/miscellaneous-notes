一、八股文
	1.为什么要使用MQ
		核心：解耦，异步，削峰
		1）解耦：假设A系统发送数据到BCD三个系统，通过接口调用发送。这个时候如果E系统也需要数据，C系统不需要数据了。那么就需要修改A系统，之间要种耦合。如果说使用MQ，A系统产生一条数据，发送到MQ里面去，哪个系统需要数据自己去MQ里面消费就行。如果新系统需要数据，直接从MQ里消费即可；如果某个系统不需要这条数据了，就取消对MQ消息的消费即可。这样下来，A系统压根儿不需要考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。
		2）异步：A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要3ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是3+300+450+200=953ms，接近1s。但是，用户通过浏览器发送请求，如果使用MQ，那么A系统连续发送3条消息到MQ队列中，假如消耗5ms，A系统从接收一个请求到返回响应给用户，总时长是3+5=8ms。
		3）削峰：减少高峰时期对服务器压力。
	2.MQ有什么优缺点
		优点就是：解耦、异步、削峰。
		
		缺点有以下几个：
			①系统可用性降低：系统引入的外部依赖越多，越容易挂掉。万一MQ挂了，MQ一挂，整体系统奔溃。
			②系统复杂度提高：加个MQ进来，那么如果保证消息没有重复消费？怎么处理消息丢失的情况？这么保证消息传递的顺序性？带来了这样的一些问题。
			③一致性问题：A系统处理完了直接返回成功了，人都以为这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，那就出现了数据不一致了。
	3.Kafka、ActiveMQ、RabbitMQ、RocketMQ有什么区别？
		对于吞吐量来说kafka和RocketMQ支撑高吞吐，activeMQ和rabbitMQ比他们低一个数量级。对于延迟量来说RabbitMQ是最低的。
		①从社区活跃度
			按照目前网络上的资料，RabbitMQ、activeMQ、zeroMQ三者中，综合来看，RabbitMQ是首选。
		②持久化消息比较
			ActiveMq和RabbitMq都支持。持久化消息主要是指我们机器在不可抗力因素等情况下挂掉了，消息不会丢失的机制。
		③综合技术实现
			可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。
			
			RabbitMQ/Kafka最好，ActiveMq次之，ZeroMq最差。
		④高并发
			毋庸置疑，RabbitMQ最高，原因是它的实现语言是天生具备高并发高可用的erlang语言
		⑤比较关注的比较，RabbitMQ和Kafka
			RabbitMQ比Kafka成熟，在可用性上，稳定性上，可靠性上，RabbitMQ胜于Kafka。
			
			另外，Kafka的定位主要在日志方面，因为Kafka设计的初衷就是处理日志的，可以看作是一个日志(消息)系统一个重要组件，针对性很强，所以如果业务方面还是建议选择RabbitMQ。
			
			还有就是，Kafka的性能(吞吐量、TPS)比RabbitMQ要高出来很多。
	4.如果保证高可用的？
		Kafka一个最基本的架构认识：有多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。这就是天然的分布式消息队列，就是说一个topic数据，是分散放在多个机器上，每个机器就放一部分数据。Kafka0.8以后，提供了HA机制，就是replica(复制品)副本机制。每个Partition的数据都会同步到其他机器上，形成自己的多个replica副本。所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上的数据即可。只能读写leader？很简单，要是可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。Kafka会均匀地将一个partition的所有replica分布在不同机器上，这样才可以提高容错性。因为如果某个broker宕机了，没关系，那个broker上面的partition在其他机器上都是有副本的，如果这上面有某个partition的leader，那么此时会从follower中重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到follower的ack之后，就会返回写成功的消息给生产者。消费的时候，只会从leader去读，但是只有当一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。
	5.如果保证消息的可靠传输？如果消息丢了怎么办？
		数据的丢失问题，可能出现在生产者、MQ、消费者中
		生产者丢失：生产者将数据发送到RabbitMQ的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息没有被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。吞吐量会下来，因为太耗性能。所以一般来说，如果你要确保说写RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你这个消息ok了。如果RabbitMQ没能处理这个消息，会回调一个nack接口，告诉你这个消息接收失败了，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。事务机制和confirm最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在哪儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失都是用confirm机制的。
		MQ中丢失：就是RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。设置持久化有两个步骤：创建queue的时候将其设置为持久化，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue的的数据。第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重复恢复queue，恢复这个queue里的数据。持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，也是可以自己重发的。注意，哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果不巧，此时RabbitMQ挂了，就会导致内存里的一点点数据丢失。
		消费端丢失：消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ认为你都消费了，这数据就丢了。这个时候得用RabbitMQ提供的ack机制，简单来说，就是你关闭RabbitMQ的自动ack，可以通过一个api来调用就行，然后每次你自己代码里确认处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。
		
		总结下来就是：
										
		RabbitMQ消息丢失及对应解决方案:
			①生产者:
				方案1：开启RabbitMQ事务(同步，不推荐)
				方案2：开启confirm模式(异步，推荐)
			②MQ:
				方案:开启RabbitMQ持久化
			③消费者:
				方案:关闭RabbitMQ自动ACK
	6.如果保证消息的顺序性
		先看看顺序会错乱的场景：RabbitMQ:一个queue，多个consumer，这不明显乱了。
		解决:拆分成多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理。
	7.如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？
		消息积压处理办法:临时紧急扩容:
		先修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉。新建一个topic，partition是原来的10倍，临时建立好原先10倍的queue数量。然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue。接着临时征用10倍的机器来部署consumer，每一个consumer消费一个临时queue的数据。这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据。等快速消费完积压数据之后，得恢复原先部署的架构，重新用原来的consumer机器来消费信息。MQ中消息失效：假设你用的是RabbitMQ，RabbitMQ是可以设置过期时间的，也就是TTL。如果消息在queue中积压超过一定的时间就会被RabbitMQ清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，就是大量积压的时候，直接丢弃数据，等到晚上12点之后，开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把之前丢的数据给他补回来。	
		mq消息队列块满了:如果消息积压在mq里，很长时间都没有处理掉，此时导致mq都快写满了，咋办？还有别的办法吗？没有，谁让第一个方案执行的太慢了，临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。
	8.让你来设计一个消息队列，你会怎么设计？
		比如说这个消息队列系统，我们从以下几个角度来考虑一下:
		
		首先这个mq得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参考一下kafka的设计理念，broker -> topic -> partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了。
		其次你得考虑一下这个mq的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢失了。那落地磁盘的怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。
		
		其次还得考虑下mq的可用性。具体参考之前可用性那个环节讲解的kafka的高可用保障机制。多副本->leader&follower->broker挂了重新选举leader即可对外服务。
		
		能不能支持数据0丢失啊？可以的，参考我们之前说的那个kafka数据零丢失方案。